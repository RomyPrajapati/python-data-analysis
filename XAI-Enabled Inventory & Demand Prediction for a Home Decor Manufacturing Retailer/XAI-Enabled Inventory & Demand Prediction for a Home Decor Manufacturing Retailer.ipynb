{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c40b1fe-d459-4ce5-b09f-9c318bdf6146",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'n_estimators' parameter of RandomForestRegressor must be an int in the range [1, inf). Got {'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False, 'random_state': 42, 'n_jobs': -1} instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 30\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[1;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(\n\u001b[1;32m     20\u001b[0m     {\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m      }\n\u001b[1;32m     29\u001b[0m  )\n\u001b[0;32m---> 30\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Identify a game theory-based XAI method\u001b[39;00m\n\u001b[1;32m     34\u001b[0m xai \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1382\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1377\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1378\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1379\u001b[0m )\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[1;32m   1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:436\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m     validate_parameter_constraints(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameter_constraints,\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    439\u001b[0m         caller_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    440\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:98\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'n_estimators' parameter of RandomForestRegressor must be an int in the range [1, inf). Got {'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False, 'random_state': 42, 'n_jobs': -1} instead."
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "\n",
    "# Load a sample of the data and the models\n",
    "X_train = pd.read_csv(\"data/X_train.csv\").sample(500, random_state=42)\n",
    "X_test = pd.read_csv(\"data/X_test.csv\").sample(500, random_state=42)\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")[\"nextmonth__home_decor\"].sample(500, random_state=42)\n",
    "y_test = pd.read_csv(\"data/y_test.csv\")[\"nextmonth__home_decor\"].sample(500, random_state=42)\n",
    "model = joblib.load(\"data/model.pkl\")\n",
    "knn_model = joblib.load(\"data/knn_model.pkl\")\n",
    "\n",
    "# Here is a view of how the RandomForestRegressor model was fitted:\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(\n",
    "    {\n",
    "        \"max_depth\": 16,\n",
    "         \"min_samples_split\": 12,\n",
    "         \"min_samples_leaf\": 7,\n",
    "         \"max_features\": \"sqrt\",\n",
    "         \"bootstrap\": False,\n",
    "         \"random_state\": 42,\n",
    "         \"n_jobs\": -1,\n",
    "     }\n",
    " )\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Identify a game theory-based XAI method\n",
    "\n",
    "xai = \"shap\"\n",
    "\n",
    "# Import this library\n",
    "import shap\n",
    "\n",
    "# Compute feature importance based on the model's predictions on X_test. Extract the top five features and store them as a set in top_feats\n",
    "\n",
    "# Use Shap's TreeExplainer since RandomForestRegressor is a Tree-based model\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importance = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# Create a DataFrame of the feature importance\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {\"Feature\": X_test.columns, \"Importance\": feature_importance}\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Top five most impactful features based on SHAP\n",
    "top_feats = feature_importance_df.head(5)\n",
    "\n",
    "# Evaluate the consistency of feature importance explanations across the two models provided\n",
    "\n",
    "# Here is a view of how the k-NN model was fitted:\n",
    "knn_model = KNeighborsRegressor(\n",
    "     n_neighbors=80,\n",
    "     weights=\"uniform\",\n",
    "     algorithm=\"auto\",\n",
    "     leaf_size=30,\n",
    "     p=2,\n",
    "     metric=\"minkowski\",\n",
    "     metric_params=None,\n",
    "     n_jobs=-1,\n",
    " )\n",
    "\n",
    "# Create a SHAP Kernel Explainer\n",
    "knn_explainer = shap.KernelExplainer(knn_model.predict, shap.kmeans(X_test, 5))\n",
    "\n",
    "# Calculate SHAP values\n",
    "knn_shap_values = knn_explainer.shap_values(X_test.sample(50, random_state=42))\n",
    "\n",
    "# Get feature importance\n",
    "knn_feature_importance = np.abs(knn_shap_values).mean(axis=0)\n",
    "\n",
    "# Create a DataFrame of the feature importance\n",
    "knn_feature_importance_df = pd.DataFrame(\n",
    "  {\"Feature\": X_test.columns, \"Importance\": knn_feature_importance}\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Top five most impactful features based on SHAP\n",
    "knn_top_feats = knn_feature_importance_df.head(5)\n",
    "\n",
    "# Calculate cosine similarty consistency across both models\n",
    "consistency = round(\n",
    "    cosine_similarity([feature_importance], [knn_feature_importance])[0][0], 2\n",
    ")\n",
    "print(\"Consistency between SHAP values:\", consistency)\n",
    "\n",
    "# The marketing team wants to know if your models are stable and reliable. What is your response?\n",
    "reliable = \"yes\"\n",
    "\n",
    "# As you're working with a smaller sample of the dataset for faster run times, you may or may not have had similar categories appear in the top features. Try running through the project again after submitting and use the full dataset to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95773f03-6333-45b2-bc11-62f18feb9d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
