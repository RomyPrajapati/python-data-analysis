{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c40b1fe-d459-4ce5-b09f-9c318bdf6146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82e7712b7e84c7fb1ea5382715f3e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency between SHAP values: 0.69\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sys\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Import this library\n",
    "import shap\n",
    "# Load a sample of the data and the models\n",
    "X_train = pd.read_csv(\"data/X_train.csv\").sample(500, random_state=42)\n",
    "X_test = pd.read_csv(\"data/X_test.csv\").sample(500, random_state=42)\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")[\"nextmonth__home_decor\"].sample(500, random_state=42)\n",
    "y_test = pd.read_csv(\"data/y_test.csv\")[\"nextmonth__home_decor\"].sample(500, random_state=42)\n",
    "model = joblib.load(\"data/model.pkl\")\n",
    "knn_model = joblib.load(\"data/knn_model.pkl\")\n",
    "\n",
    "# Here is a view of how the RandomForestRegressor model was fitted:\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,  # Add this required parameter\n",
    "    max_depth=16,\n",
    "    min_samples_split=12,\n",
    "    min_samples_leaf=7,\n",
    "    max_features=\"sqrt\",\n",
    "    bootstrap=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Identify a game theory-based XAI method\n",
    "\n",
    "xai = \"shap\"\n",
    "\n",
    "\n",
    "\n",
    "# Compute feature importance based on the model's predictions on X_test. Extract the top five features and store them as a set in top_feats\n",
    "\n",
    "# Use Shap's TreeExplainer since RandomForestRegressor is a Tree-based model\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importance = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# Create a DataFrame of the feature importance\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {\"Feature\": X_test.columns, \"Importance\": feature_importance}\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Top five most impactful features based on SHAP\n",
    "top_feats = feature_importance_df.head(5)\n",
    "\n",
    "# Evaluate the consistency of feature importance explanations across the two models provided\n",
    "\n",
    "# Here is a view of how the k-NN model was fitted:\n",
    "knn_model = KNeighborsRegressor(\n",
    "     n_neighbors=80,\n",
    "     weights=\"uniform\",\n",
    "     algorithm=\"auto\",\n",
    "     leaf_size=30,\n",
    "     p=2,\n",
    "     metric=\"minkowski\",\n",
    "     metric_params=None,\n",
    "     n_jobs=-1,\n",
    " )\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Create a SHAP Kernel Explainer\n",
    "knn_explainer = shap.KernelExplainer(knn_model.predict, shap.kmeans(X_test, 5))\n",
    "\n",
    "# Calculate SHAP values\n",
    "knn_shap_values = knn_explainer.shap_values(X_test.sample(50, random_state=42))\n",
    "\n",
    "# Get feature importance\n",
    "knn_feature_importance = np.abs(knn_shap_values).mean(axis=0)\n",
    "\n",
    "# Create a DataFrame of the feature importance\n",
    "knn_feature_importance_df = pd.DataFrame(\n",
    "  {\"Feature\": X_test.columns, \"Importance\": knn_feature_importance}\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Top five most impactful features based on SHAP\n",
    "knn_top_feats = knn_feature_importance_df.head(5)\n",
    "\n",
    "# Calculate cosine similarty consistency across both models\n",
    "consistency = round(\n",
    "    cosine_similarity([feature_importance], [knn_feature_importance])[0][0], 2\n",
    ")\n",
    "print(\"Consistency between SHAP values:\", consistency)\n",
    "\n",
    "# The marketing team wants to know if your models are stable and reliable. What is your response?\n",
    "reliable = \"yes\"\n",
    "\n",
    "# As you're working with a smaller sample of the dataset for faster run times, you may or may not have had similar categories appear in the top features. Try running through the project again after submitting and use the full dataset to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95773f03-6333-45b2-bc11-62f18feb9d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
