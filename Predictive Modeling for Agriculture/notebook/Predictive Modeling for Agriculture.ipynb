{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0eb4f16-5a99-460d-a5ba-706b7ef0bbe7",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 14,
    "id": "bA5ajAmk7XH6",
    "lastExecutedAt": 1707317470036,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# All required libraries are imported here for you.\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\n# Load the dataset\ncrops = pd.read_csv(\"soil_measures.csv\")\n\n# Write your code here"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for N: 0.09149868209906838\n",
      "F1-score for P: 0.1476194290972821\n",
      "F1-score for K: 0.23896974566001802\n",
      "F1-score for ph: 0.0458225366614312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'K': 0.23896974566001802}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All required libraries are imported here for you.\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# Load the dataset\n",
    "crops = pd.read_csv(\"soil_measures.csv\")\n",
    "\n",
    "# Check for missing values\n",
    "crops.isna().sum()\n",
    "\n",
    "# Check how many crops we have, i.e., multi-class target\n",
    "crops.crop.unique()\n",
    "\n",
    "# Split into feature and target sets\n",
    "X = crops.drop(columns=\"crop\")\n",
    "y = crops[\"crop\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create a dictionary to store the model performance for each feature\n",
    "feature_performance = {}\n",
    "\n",
    "# Train a logistic regression model for each feature\n",
    "for feature in [\"N\", \"P\", \"K\", \"ph\"]:\n",
    "    log_reg = LogisticRegression(C=1.0,\n",
    "    penalty='l2',\n",
    "    solver='lbfgs',\n",
    "    max_iter=100,\n",
    "    random_state=42)\n",
    "    log_reg.fit(X_train[[feature]], y_train)\n",
    "    y_pred = log_reg.predict(X_test[[feature]])\n",
    "    \n",
    "    # Calculate F1 score, the harmonic mean of precision and recall\n",
    "    # Could also use balanced_accuracy_score\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    \n",
    "    # Add feature-f1 score pairs to the dictionary\n",
    "    feature_performance[feature] = f1\n",
    "    print(f\"F1-score for {feature}: {f1}\")\n",
    "\n",
    "# K produced the best F1 score\n",
    "# Store in best_predictive_feature dictionary\n",
    "best_predictive_feature = {\"K\": feature_performance[\"K\"]}\n",
    "best_predictive_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43847b85-355c-42f2-ad3a-6bfadd7661cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
